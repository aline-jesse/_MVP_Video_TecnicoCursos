/**
 * üß™ Testes de Precis√£o de Lip-Sync
 * FASE 2: Sprint 1 - Valida√ß√£o espec√≠fica de precis√£o ‚â•95%
 */

import { audio2FaceService } from '@/lib/services/audio2face-service'
import { avatar3DPipeline } from '@/lib/avatar-3d-pipeline'

describe('Lip-Sync Accuracy Validation', () => {
  const MINIMUM_ACCURACY = 95 // Requisito: ‚â•95%
  
  describe('Cen√°rios de Teste Portugu√™s Brasileiro', () => {
    const testScenarios = [
      {
        category: 'Fonemas B√°sicos',
        cases: [
          { text: 'Papai', phonemes: ['p', 'a'], difficulty: 'easy' },
          { text: 'Mam√£e', phonemes: ['m', 'a', '√£'], difficulty: 'easy' },
          { text: 'Beb√™', phonemes: ['b', 'e'], difficulty: 'easy' },
          { text: 'Vov√≥', phonemes: ['v', 'o'], difficulty: 'medium' },
          { text: 'Fofoca', phonemes: ['f', 'o', 'k'], difficulty: 'medium' }
        ]
      },
      {
        category: 'Palavras Complexas',
        cases: [
          { text: 'Extraordin√°rio', phonemes: ['ks', 'tr', 'r'], difficulty: 'hard' },
          { text: 'Paralelep√≠pedo', phonemes: ['p', 'r', 'l'], difficulty: 'hard' },
          { text: 'Pneum√°tico', phonemes: ['pn', 'eu'], difficulty: 'hard' },
          { text: 'Psicologia', phonemes: ['ps', 'k'], difficulty: 'hard' }
        ]
      },
      {
        category: 'Frases Naturais',
        cases: [
          { 
            text: 'Bom dia, como voc√™ est√°?', 
            phonemes: ['b', 'm', 'd', 'k', 'v', 's'], 
            difficulty: 'medium' 
          },
          { 
            text: 'A tecnologia avan√ßa rapidamente.', 
            phonemes: ['t', 'k', 'n', 'v', 'r'], 
            difficulty: 'medium' 
          },
          { 
            text: 'Precisamos verificar a sincroniza√ß√£o labial.', 
            phonemes: ['p', 'r', 's', 'v', 'f', 'k', 's', 'n', 'k', 'r', 'n', 'z', 'l', 'b'], 
            difficulty: 'hard' 
          }
        ]
      }
    ]

    testScenarios.forEach(scenario => {
      describe(scenario.category, () => {
        scenario.cases.forEach(testCase => {
          test(`deve atingir ‚â•${MINIMUM_ACCURACY}% para "${testCase.text}" (${testCase.difficulty})`, async () => {
            const sessionId = await audio2FaceService.createSession({
              instanceName: `test-${testCase.difficulty}`,
              avatarPath: '/test/avatar.usd'
            })

            try {
              // Gerar √°udio com caracter√≠sticas espec√≠ficas para o teste
              const audioBuffer = await generatePhonemeAudio(testCase.text, testCase.phonemes)
              
              const result = await audio2FaceService.processAudio(sessionId, audioBuffer, {
                outputFormat: 'arkit',
                frameRate: 60,
                quality: 'high',
                language: 'pt-BR'
              })

              // Valida√ß√µes principais
              expect(result.success).toBe(true)
              expect(result.accuracy).toBeGreaterThanOrEqual(MINIMUM_ACCURACY)
              
              // Valida√ß√µes espec√≠ficas por dificuldade
              if (testCase.difficulty === 'easy') {
                expect(result.accuracy).toBeGreaterThanOrEqual(98) // Casos f√°ceis devem ter alta precis√£o
              } else if (testCase.difficulty === 'medium') {
                expect(result.accuracy).toBeGreaterThanOrEqual(96)
              } else if (testCase.difficulty === 'hard') {
                expect(result.accuracy).toBeGreaterThanOrEqual(MINIMUM_ACCURACY)
              }

              // Validar detec√ß√£o de fonemas espec√≠ficos
              const detectedPhonemes = extractPhonemes(result.lipSyncData)
              testCase.phonemes.forEach(phoneme => {
                expect(detectedPhonemes).toContain(phoneme)
              })

              console.log(`‚úÖ ${testCase.difficulty.toUpperCase()}: "${testCase.text}" - ${result.accuracy}%`)
              
            } finally {
              await audio2FaceService.destroySession(sessionId)
            }
          }, 45000)
        })
      })
    })
  })

  describe('Testes de Stress de Precis√£o', () => {
    test('deve manter precis√£o ‚â•95% com m√∫ltiplas sess√µes simult√¢neas', async () => {
      const concurrentSessions = 3
      const testText = 'Teste de stress para m√∫ltiplas sess√µes simult√¢neas'
      
      const sessionPromises = Array.from({ length: concurrentSessions }, async (_, index) => {
        const sessionId = await audio2FaceService.createSession({
          instanceName: `stress-test-${index}`,
          avatarPath: '/test/avatar.usd'
        })

        try {
          const audioBuffer = await generateTestAudio(testText, 'pt-BR')
          const result = await audio2FaceService.processAudio(sessionId, audioBuffer, {
            outputFormat: 'arkit',
            frameRate: 60,
            quality: 'high'
          })

          return {
            sessionIndex: index,
            accuracy: result.accuracy,
            success: result.success
          }
        } finally {
          await audio2FaceService.destroySession(sessionId)
        }
      })

      const results = await Promise.all(sessionPromises)
      
      // Validar que todas as sess√µes foram bem-sucedidas
      results.forEach(result => {
        expect(result.success).toBe(true)
        expect(result.accuracy).toBeGreaterThanOrEqual(MINIMUM_ACCURACY)
      })

      const averageAccuracy = results.reduce((sum, r) => sum + r.accuracy, 0) / results.length
      expect(averageAccuracy).toBeGreaterThanOrEqual(MINIMUM_ACCURACY)

      console.log(`‚úÖ Stress test: ${concurrentSessions} sess√µes, precis√£o m√©dia: ${averageAccuracy.toFixed(2)}%`)
    }, 90000)

    test('deve manter precis√£o com √°udio de diferentes qualidades', async () => {
      const qualityTests = [
        { quality: 'low', sampleRate: 22050, expectedMinAccuracy: 93 },
        { quality: 'medium', sampleRate: 44100, expectedMinAccuracy: 95 },
        { quality: 'high', sampleRate: 48000, expectedMinAccuracy: 97 }
      ]

      const testText = 'Teste de qualidade de √°udio para sincroniza√ß√£o labial'

      for (const qualityTest of qualityTests) {
        const sessionId = await audio2FaceService.createSession({
          instanceName: `quality-test-${qualityTest.quality}`,
          avatarPath: '/test/avatar.usd'
        })

        try {
          const audioBuffer = await generateTestAudio(
            testText, 
            'pt-BR', 
            qualityTest.sampleRate
          )
          
          const result = await audio2FaceService.processAudio(sessionId, audioBuffer, {
            outputFormat: 'arkit',
            frameRate: 60,
            quality: qualityTest.quality as 'low' | 'medium' | 'high'
          })

          expect(result.success).toBe(true)
          expect(result.accuracy).toBeGreaterThanOrEqual(qualityTest.expectedMinAccuracy)

          console.log(`‚úÖ Quality ${qualityTest.quality}: ${result.accuracy}% (min: ${qualityTest.expectedMinAccuracy}%)`)
          
        } finally {
          await audio2FaceService.destroySession(sessionId)
        }
      }
    }, 60000)
  })

  describe('Valida√ß√£o de M√©tricas de Qualidade', () => {
    test('deve fornecer m√©tricas detalhadas de qualidade', async () => {
      const sessionId = await audio2FaceService.createSession({
        instanceName: 'metrics-test',
        avatarPath: '/test/avatar.usd'
      })

      try {
        const testText = 'An√°lise detalhada de m√©tricas de qualidade de sincroniza√ß√£o'
        const audioBuffer = await generateTestAudio(testText, 'pt-BR')
        
        const result = await audio2FaceService.processAudio(sessionId, audioBuffer, {
          outputFormat: 'arkit',
          frameRate: 60,
          quality: 'high',
          includeMetrics: true
        })

        // Validar m√©tricas b√°sicas
        expect(result.accuracy).toBeGreaterThanOrEqual(MINIMUM_ACCURACY)
        expect(result.metadata).toBeDefined()
        expect(result.metadata.frameRate).toBe(60)
        expect(result.metadata.totalFrames).toBeGreaterThan(0)

        // Validar m√©tricas avan√ßadas se dispon√≠veis
        if (result.qualityMetrics) {
          expect(result.qualityMetrics.phonemeAccuracy).toBeGreaterThanOrEqual(90)
          expect(result.qualityMetrics.temporalConsistency).toBeGreaterThanOrEqual(85)
          expect(result.qualityMetrics.visualRealism).toBeGreaterThanOrEqual(80)
        }

        console.log('‚úÖ Quality metrics:', {
          accuracy: result.accuracy,
          phonemeAccuracy: result.qualityMetrics?.phonemeAccuracy,
          temporalConsistency: result.qualityMetrics?.temporalConsistency,
          visualRealism: result.qualityMetrics?.visualRealism
        })

      } finally {
        await audio2FaceService.destroySession(sessionId)
      }
    }, 30000)
  })
})

/**
 * Fun√ß√£o auxiliar para gerar √°udio com fonemas espec√≠ficos
 */
async function generatePhonemeAudio(text: string, phonemes: string[], sampleRate = 44100): Promise<Buffer> {
  // Simular gera√ß√£o de √°udio com caracter√≠sticas espec√≠ficas para fonemas
  const audioLength = text.length * 80 // ~80ms por caractere para fala clara
  const samples = Math.floor(audioLength * sampleRate / 1000)
  const buffer = Buffer.alloc(samples * 2)
  
  // Gerar padr√µes de frequ√™ncia baseados nos fonemas
  for (let i = 0; i < samples; i++) {
    let frequency = 200 // Frequ√™ncia base
    
    // Ajustar frequ√™ncia baseada nos fonemas presentes
    phonemes.forEach(phoneme => {
      switch (phoneme) {
        case 'p': case 'b': frequency += 100; break
        case 'm': case 'n': frequency += 150; break
        case 'v': case 'f': frequency += 200; break
        case 'a': frequency += 300; break
        case 'e': frequency += 250; break
        case 'o': frequency += 180; break
        default: frequency += 50
      }
    })
    
    const time = i / sampleRate
    const amplitude = Math.sin(2 * Math.PI * frequency * time) * 
                     Math.sin(2 * Math.PI * (frequency * 0.5) * time) * 
                     32767 * 0.7
    
    buffer.writeInt16LE(amplitude, i * 2)
  }
  
  return buffer
}

/**
 * Fun√ß√£o auxiliar para extrair fonemas dos dados de lip-sync
 */
function extractPhonemes(lipSyncData: any[]): string[] {
  // Simular extra√ß√£o de fonemas dos dados ARKit
  const detectedPhonemes: string[] = []
  
  lipSyncData.forEach(frame => {
    // Analisar blendshapes para detectar fonemas
    if (frame.jawOpen > 0.5) detectedPhonemes.push('a', 'o')
    if (frame.mouthClose > 0.7) detectedPhonemes.push('p', 'b', 'm')
    if (frame.mouthFunnel > 0.6) detectedPhonemes.push('o', 'u')
    if (frame.mouthPucker > 0.5) detectedPhonemes.push('u')
    if (frame.mouthLeft > 0.4 || frame.mouthRight > 0.4) detectedPhonemes.push('e', 'i')
  })
  
  return [...new Set(detectedPhonemes)] // Remover duplicatas
}

/**
 * Fun√ß√£o auxiliar para gerar √°udio de teste com sample rate espec√≠fico
 */
async function generateTestAudio(text: string, language: string, sampleRate = 44100): Promise<Buffer> {
  const audioLength = text.length * 60 // ~60ms por caractere
  const samples = Math.floor(audioLength * sampleRate / 1000)
  const buffer = Buffer.alloc(samples * 2)
  
  for (let i = 0; i < samples; i++) {
    const frequency = 440 + Math.sin(i / 2000) * 200 // Varia√ß√£o natural de voz
    const amplitude = Math.sin(2 * Math.PI * frequency * i / sampleRate) * 32767 * 0.8
    buffer.writeInt16LE(amplitude, i * 2)
  }
  
  return buffer
}